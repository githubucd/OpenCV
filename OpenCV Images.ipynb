{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Operations On Images With OpenCV\n",
    "Email : <a href='mailto:madani.a@ucd.ac.ma'>madani.a@ucd.ac.ma</a>\n",
    "<img src='images/opencv.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images Using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "# Colored Image\n",
    "img1 = cv2.imread(\"messi5.jpg\",1)\n",
    "#Black and White Image (Gray Scale)\n",
    "img2 = cv2.imread(\"messi5.jpg\",0)\n",
    "cv2.imshow(\"couleur\",img1)\n",
    "#cv2.imshow(\"niveaux de gris\",img2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1) #For Mac only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explications\n",
    "Dans cet exemple, nous avons :\n",
    "<ul>\n",
    "    <li>importé le module OpenCV</li>\n",
    "    <li>fait la lecture d'une image couleur (RGB). Le chemin complet de l'image (sous forme absolue ou relative) doit être fournit</li>\n",
    "    <li>fait la lecture d'une image en noir et blanc (en niveaus de gris)</li>\n",
    "    <li>afficher l'image dans une fenêtre\n",
    "</ul>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Shape / Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarque\n",
    "Python stocke les images comme des tableaux NumPy, i.e. des matrices de nombres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 54 121  89]\n",
      "  [ 54 121  89]\n",
      "  [ 53 120  88]\n",
      "  ...\n",
      "  [ 60 120  89]\n",
      "  [ 60 120  89]\n",
      "  [ 60 120  89]]\n",
      "\n",
      " [[ 54 121  89]\n",
      "  [ 54 121  89]\n",
      "  [ 53 120  88]\n",
      "  ...\n",
      "  [ 60 120  89]\n",
      "  [ 60 120  89]\n",
      "  [ 60 120  89]]\n",
      "\n",
      " [[ 54 121  89]\n",
      "  [ 54 121  89]\n",
      "  [ 53 120  88]\n",
      "  ...\n",
      "  [ 59 119  88]\n",
      "  [ 59 119  88]\n",
      "  [ 59 119  88]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 66 137 104]\n",
      "  [ 64 135 102]\n",
      "  [ 55 126  93]\n",
      "  ...\n",
      "  [ 50 117  85]\n",
      "  [ 39 106  74]\n",
      "  [ 31  98  66]]\n",
      "\n",
      " [[ 62 133 100]\n",
      "  [ 60 131  98]\n",
      "  [ 53 124  91]\n",
      "  ...\n",
      "  [ 49 116  84]\n",
      "  [ 38 105  73]\n",
      "  [ 30  97  65]]\n",
      "\n",
      " [[ 58 129  96]\n",
      "  [ 58 129  96]\n",
      "  [ 51 122  89]\n",
      "  ...\n",
      "  [ 47 114  82]\n",
      "  [ 38 105  73]\n",
      "  [ 32  99  67]]]\n"
     ]
    }
   ],
   "source": [
    "print(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[104 104 103 ... 104 104 104]\n",
      " [104 104 103 ... 104 104 104]\n",
      " [104 104 103 ... 103 103 103]\n",
      " ...\n",
      " [119 117 108 ... 100  89  81]\n",
      " [115 113 106 ...  99  88  80]\n",
      " [111 111 104 ...  97  88  82]]\n"
     ]
    }
   ],
   "source": [
    "print(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La taille de la matrice représentant l'image img1 (qui est une image couleur) est 600 lignes, 1100 colonnes et 3 canneaux (Channels). Les trois cannaux représentent les couleurs de bases : RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1100)\n"
     ]
    }
   ],
   "source": [
    "print(img2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La taille de la matrice représentant l'image img2 (qui est une image en noir et blanc) est 600 lignes, 1100 colonnes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display The Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img=cv2.imread(\"messi5.jpg\",0)\n",
    "cv2.imshow(\"Messi\", img)\n",
    "cv2.waitKey(2000)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explications\n",
    "1. Charge une image. Le deuxième paramètres (0) indique que l'image est en noir et blanc. On peut utiliser la valeur 1 pour charger une image couleur\n",
    "3. Ouvre une fenêtre pour afficher l'image. Le premier paramètre indique le nom de la fenêtre, alors que le deuxième paramètres précise l'objet image à afficher\n",
    "5. Attendre un délai. Ici 2000 millisecondes. Si à la place du délai, vous indiquez la valeur 0, la fenêtre sera affichée jusqu'à ce que l'utilisateur presse une touche, comme dans l'exemple suivant.\n",
    "7. Fermer toutes les fenêtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"Messi5.jpg\",0)\n",
    "\n",
    "cv2.imshow(\"Messi\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut indiquer une touche qui sera pressée pour que la fenêtre soit fermée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread(\"Messi5.jpg\",0)\n",
    "\n",
    "cv2.imshow(\"Messi\", img)\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "\n",
    "if key==27 or key==ord('q'):\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exemple, la fenêtre sera fermée si l'utilisateur appuie sur la touche echappe (code 27) ou la touche 'q'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accès aux pixels d'une image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple suivant, on va lire le contenu du pixel (0,0) de notre image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('Messi5.jpg')\n",
    "\"\"\"\n",
    "Lecture du pixel (0,0).\n",
    "N'oubliez pas que OpenCV utilise l'espace BGR et non pas RGB\n",
    "b=blue, g=green, r=red\n",
    "\"\"\"\n",
    "(b, g, r) = image[0,0]\n",
    "# on affiche les 3 intensites representant notre couleur\n",
    "print (b,g,r) \n",
    "# On change la couleur du pixel (0,0). (255,255,255) :  blanc\n",
    "image[0,0] = (255,255,255)\n",
    "#On récupère à nouveau le pixel (0,0)\n",
    "(b, g, r) = image[0,0]\n",
    "\n",
    "print (b,g,r) \n",
    "\n",
    "cv2.imshow(\"test\", image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyWindow(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Comme on peut le voir dans l'exemple précédent, l'utilsation de crochets  permet de naviguer dans une image. Ainsi image[0,0] nous renvoie la valeur du pixel situé à la ligne 0 et la colonne 0.\n",
    "</p>\n",
    "<p>\n",
    "Ces crochets peuvent aussi nous permettre de saisir une partie de l'image. Ainsi si on écris image[0:100 , 0:100] cela va retourner un carré de 100 pixels de coté allant du pixel (0,0) au pixel (100,100). Le pixel (0,0) se situe en haut à gauche de notre image et le pixel (100,100) se situe 100 pixels plus à droite et plus à bas.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#Chargement d'une image initiale\n",
    "image = cv2.imread('Messi5.jpg')\n",
    "#creation d'une autre image à partir de l'image initiale\n",
    "#Cette nouvelle image, appelée coin, est un carre de 200 pixels de cote\n",
    "coin = image[0:200, 0:200]\n",
    " #affichage des deux images\n",
    "cv2.imshow(\"Image Initiale\", image)\n",
    "cv2.imshow(\"Coin\", coin)\n",
    "# affichage de l'image tant que je n'appuie pas sur une touche\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut utiliser aussi les crochets pour modifier une partie d'une image, comme dans l'exemple suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "#Chargement d'une image\n",
    "image = cv2.imread('Messi5.jpg')\n",
    "#Taille de l'image. \n",
    "height=image.shape[0]\n",
    "width=image.shape[1]\n",
    "#Changement de couleur des coins supérieur droit et inférieur gauche\n",
    "image[0:200, 0:200]=(255, 0,0)\n",
    "image[height-200:height-1, width-200:width-1]=(0, 0,255)\n",
    " #affichage des deux images\n",
    "cv2.imshow(\"Image Modifiée\", image)\n",
    "# affichage de l'image tant que je n'appuie pas sur une touche\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resizing The Image\n",
    "La méthode <b>resize</b> de OpenCV permet de redimensionner une image. Le premier paramètre est l'image à traiter, le deuxième paramètre (tuple) est la nouvelle dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"carwash.jpg\",0)\n",
    "\n",
    "resized_img=cv2.resize(img, (600,500))\n",
    "\n",
    "cv2.imshow(\"Car Wash\", resized_img)\n",
    "\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explications\n",
    "Ligne 3 : Change la taille de l'image. Les valeurs (600, 500) représentent les nouvelles dimensions de l'image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarque :\n",
    "En changeant la taille d'une image avec la méthode <b>resize()</b>, on risque d'avoir une image qui n'est pas symétrique. Une façon de remédier à ce problème est de donner une taille proportionnelle. Par exemple : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"carwash.jpg\",0)\n",
    "\n",
    "resized_img=cv2.resize(img, (int(img.shape[1]*2),int(img.shape[0]*2)))\n",
    "\n",
    "cv2.imshow(\"Car Wash\", resized_img)\n",
    "\n",
    "cv2.waitKey(2000)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write The Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour enregistrer une image sur le disque, il suffit d'utiliser la méthode <b>imwrite()</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img=cv2.imread(\"carwash.jpg\",1)\n",
    "\n",
    "cv2.imshow(\"Car Wash\", img)\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "\n",
    "if key==27:\n",
    "    cv2.destroyAllWindows()\n",
    "elif key==ord('q'):\n",
    "    cv2.imwrite(\"carwash.png\",img)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explications\n",
    "Après avoir afficher une image avec <b>imshow()</b>, on attend l'utilisateur de taper une touche. La touche echappe ferme la fenêtre, alors que la touche 's', enregistre l'image sous un autre format (ici, format png), puis ferme la fenêtre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dessiner avec OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Dans ce paragraphe, nous allons voir comment dessiner des formes plus complexes, comme des cercles, des lignes ou autres formes. Nous allons utiliser pour cela des fonctions d'OpenCV déjà toutes faites : cv2.line(), cv2.rectangle(), cv2.circle().\n",
    "</p>\n",
    "<p>\n",
    "    \n",
    "cv2.line() demande 5 arguments. Sa syntaxe est la suivante :\n",
    "    \n",
    "</p>\n",
    "<p><center><b>\n",
    "    cv2.line(canvas, (xstart, ystart), (xend, yend), (blue, green, red), (thickness))</b></center>\n",
    "</p>\n",
    "<p>\n",
    "    où :\n",
    "<ul>\n",
    "    <li>canvas est l'image sur laquelle OpenCv doit tracer une ligne</li>\n",
    "\n",
    "<li>(xstart, ystart) sont les coordonnées du point de départ de notre droite (en pixel)</li>\n",
    "\n",
    "<li>(xstart, ystart) sont les coordonnées du point d'arrivée de notre droite (en pixel)</li>\n",
    "\n",
    "<li>(blue, green, red) est la couleur de notre droite</li>\n",
    "\n",
    "<li>thickness est l'épaisseur de notre ligne (en pixel)</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p>\n",
    "Par exemple, si on souhaite tracer une droite sur notre image du pixel (0,0) au pixel (100,100) en bleu d'une épaisseur de 1 pixel, on écrira :\n",
    "</p>\n",
    "<p>\n",
    "    <center>cv2.line(image, (0,0), (100,100), (255,0,0), 1)</center>\n",
    "</p>\n",
    "<p>\n",
    "Tout comme cv2.line(), cv2.rectangle demande 5 arguments. Sa syntaxe est donnée comme suit :\n",
    "</p>\n",
    "<p><center><b>\n",
    "    cv2.rectangle(canvas, (xstart, ystart), (xend, yend), (blue, green, red), (thickness))</b></center>\n",
    "</p>\n",
    "<p>\n",
    "    où :\n",
    "</p>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>canvas est l'image sur laquelle OpenCv doit tracer un rectangle</li>\n",
    "\n",
    "<li>(xstart, ystart) sont les coordonnées du point de départ de notre rectangle (en pixel)</li>\n",
    "\n",
    "<li>(xstart, ystart) sont les coordonnées du point d'arrivée de notre rectangle (en pixel)</li>\n",
    "\n",
    "<li>(blue, green, red) est la couleur de notre rectangle</li>\n",
    "\n",
    "<li>thickness est l'épaisseur de notre rectangle(en pixel) (à noter que si vous mettez une épaisser de -1 le rectangle sera rempli)</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p>\n",
    "Normalement cette fonction ne devrait pas poser trop de problèmes vu qu'elle est quasiment identique à cv2.line().\n",
    "</p>\n",
    "<p>\n",
    "Passons maintenant à cv2.circle(). Elle aussi demande 5 arguments.\n",
    "</p>\n",
    "<p><center><b>\n",
    "    cv2.circle(canvas, (centerx, centery), radius, (blue, green, red), (thickness))</b></center>\n",
    "</p>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>canvas est l'image sur laquelle OpenCv doit tracer un rectangle</li>\n",
    "\n",
    "<li>(centerx, centery) sont les coordonnées du centre de notre cercle (en pixel)</li>\n",
    "\n",
    "<li>radius est le rayon de notre cercle (en pixel)</li>\n",
    "\n",
    "<li>(blue, green, red) est la couleur de notre cercle</li>\n",
    "\n",
    "<li>thickness est l'épaisseur de notre cercle(en pixel) (à noter que si vous mettez une épaisser de -1 le cercle sera rempli)</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p>\n",
    "Avant de passer à la pratique, nous allons voir comment créer une image entièrement vide. Par entièrement vide, on sous entend que l'image va être complètement noire. Pour cela nous allons utiliser une fonction de la librairie numpy <u>numpy.zeros()</u>. Cette fonction prend deux arguments: les dimensions de l'image à créer et son type (pour nous ce sera toujours uint8).\n",
    "</p>\n",
    "<p>\n",
    "Par exemple : l'instruction numpy.zeros((300,300,3), dtype=\"uint8\"), créée une image carrée de 300 pixels de coté entièrement noire.\n",
    "</p>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "image=np.zeros((300,300,3), dtype=\"uint8\")\n",
    "cv2.line(image,(0,0),(300,300),(255,0,0),1)\n",
    "cv2.rectangle(image,(150,0),(250,300),(0,255,0),-1)\n",
    "cv2.circle(image,(150,150), 100,(0,0,255), -1)\n",
    "cv2.imshow(\"ImageNoire\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opération sur les images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Nous allons apprendre dans ce paragraphe comment ajouter deux images en utilisant Python et OpenCV.</p>\n",
    "\n",
    "<p>Prenons d'abord deux images. Il y a une condition à respecter : les images doivent avoir exactement la même taille.</p>\n",
    "<p>Voici les images que nous allons utiliser dans nos exemples :</p>\n",
    "<p><img src=\"images/road.jpg\"></p> et <p><img src=\"images/car.jpg\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter des images\n",
    "<p>Il existe deux fonctions différentes pour ajouter les images ensemble.\n",
    "La fonction cv2.add (voir l'exemple ci-dessous) qui ajoute de manière respectivement les pixels de la première image à celle de la seconde.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_road=cv2.imread(\"images/road.jpg\")\n",
    "img_car=cv2.imread(\"images/car.jpg\")\n",
    "img_sum=cv2.add(img_road, img_car)\n",
    "cv2.imshow(\"Road\", img_road)\n",
    "cv2.imshow(\"Car\", img_car)\n",
    "cv2.imshow(\"Road & Car\", img_sum)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode n'est pas la bonne option lorsque nous voulons ajouter deux images, car elle permet d'ajouter simplement les valeurs ensemble et lorsqu'elles sont 255 ou plus, elles deviennent tout simplement blanches. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajouter des images pondérées\n",
    "<p>La première méthode peut être utilisée dans certains cas, mais parfois, nous ne voulons pas effectuer un simple ajout dans l'image. Mais au contraire, nous voulons une sorte de mélange d'images.\n",
    "</p>\n",
    "<p>Il s'agit également (dans cette deuxième méthode) d'un ajout d'images, mais différents poids sont attribués aux images afin de donner une impression de fusion ou de transparence. Les images sont ajoutées selon l'équation ci-dessous:\n",
    "</p>    \n",
    "<p>\n",
    "    <center><b>g(x) = (1 - a)f1(x) + af2(x)</b></center>\n",
    "    </p>\n",
    "    <p>En faisant varier la valeur de <b>'a'</b> de 0 à 1, vous pouvez effectuer une transition cool entre une image et une autre.</p>\n",
    "<p>Dans la deuxième méthode, donc, au lieu d'ajouter immédiatement les pixels, on prend également en compte le poids que nous voulons attribuer à chaque image.\n",
    "</p><p>\n",
    "On peut attribuer un poids de 0 à 1.\n",
    "    </p><p>\n",
    "Par exemple, si nous voulons mettre en surbrillance la voiture et afficher un arrière-plan (la route) doux, nous pourrions attribuer 0.7 à la voiture et 0.3 à l'arrière-plan.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_road=cv2.imread(\"images/road.jpg\")\n",
    "img_car=cv2.imread(\"images/car.jpg\")\n",
    "img_weighted = cv2.addWeighted(img_road, 0.3, img_car, 0.7, 0)\n",
    "cv2.imshow(\"Road\", img_road)\n",
    "cv2.imshow(\"Car\", img_car)\n",
    "cv2.imshow(\"Road & Car\", img_weighted)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogramme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qu'est ce que est un histogramme? On peut considérer un histogramme comme un graphique, ce qui nous donne une idée globale sur la distribution d'intensité d'une image. Il s'agit d'un tracé avec des valeurs de pixels (allant de 0 à 255) sur l'axe X et le nombre correspondant de pixels dans l'image sur l'axe Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>On peut considérer un histogramme comme une autre façon de comprendre l'image. En regardant un histogramme d'une image, on aura une intuition sur le contraste, la luminosité, la distribution d'intensité, etc. de cette image. Ci-dessous, un exemple d'une image et l'histogramme correspondant :</p>\n",
    "<p><img src=\"images/histogram.jpg\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'image précédente, l'histogramme est dessiné pour une image en niveaux de gris, pas une image en couleur. On peut voir l'image et son histogramme. La région gauche de l'histogramme montre la quantité de pixels qui sont plus sombres dans l'image et la région droite montre la quantité de pixels qui sont plus clairs. À partir de l'histogramme, on peut remarquer que la zone sombre est plus grande que la région qui est plus claire et que la quantité des intensités moyennes (les valeurs des pixels dans la gamme moyenne, disons environ 127) sont très inférieures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons une idée de ce qu'est un histogramme, nous pouvons voir comment le tracer. OpenCV et Numpy sont livrés avec une fonction intégrée pour cela. Avant d'utiliser ces fonctions, nous devons comprendre certaines terminologies liées aux histogrammes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>BINS</b>: l'histogramme ci-dessus montre le nombre de pixels pour chaque valeur de pixel, c'est-à-dire le nombre de pixels pour chaque valeur de 0 à 255. Nous avons besoin donc de 256 valeurs pour afficher l'histogramme ci-dessus. Mais supposons que nous n'avons pas besoin de trouver le nombre de pixels pour toutes les valeurs de pixels séparément, mais le nombre de pixels dans un intervalle de valeurs de pixels. Disons par exemple, nous devons trouver le nombre de pixels pour les plages comprises entre 0 et 15, puis 16 et 31, ..., 240 et 255. Nous n'aurons besoin que de 16 valeurs pour représenter l'histogramme.\n",
    "</p>\n",
    "<p>\n",
    "Donc, ce que nous allons faire c'est tout simplement de diviser tout l'histogramme en 16 sous-parties et la valeur de chaque sous-partie est la somme de tous les pixels. Cette sous-partie est appelée «BIN». BINS est représenté par le terme <b>histSize</b> dans les documents OpenCV.\n",
    "</p>\n",
    "<p>\n",
    "<b>DIMS</b>: C'est le nombre de paramètres pour lesquels nous collectons les données. Dans notre cas, nous collectons des données concernant une seule chose, la valeur d'intensité, d'où la valeur 1.\n",
    "</p>\n",
    "<p>\n",
    "<b>RANGE</b>: C'est la plage de valeurs d'intensité que nous souhaitons mesurer. Normalement, c'est [0,256], c'est-à-dire toutes les valeurs d'intensité.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme avec OpenCV<p>\n",
    "Pour tracer un histogramme avec OpenCV, nous utilisons la fonction <b>cv2.calcHist ()</b>. Sa syntaxe est donnée ci-dessous :\n",
    "</p>\n",
    "<p><center><b>\n",
    "cv2.calcHist (images, canaux, masque, histSize, plages [, hist [, accumuler]])\n",
    "    </b></center></p>\n",
    "<ul>\n",
    "<li><b>images</b>: c'est l'image source de type uint8 ou float32. il doit être indiqué entre crochets, c'est-à-dire \"[img]\".\n",
    "    <li><b>canaux</b>: il est également indiqué entre crochets. C'est l'indice de canal pour lequel nous calculons l'histogramme. Par exemple, si l'entrée est une image en niveaux de gris, sa valeur est [0]. Pour l'image en couleur, vous pouvez passer [0], [1] ou [2] pour calculer respectivement l'histogramme du canal bleu, vert ou rouge.\n",
    "    <li><b>mask</b>: masque de l'image. Pour trouver l'histogramme de l'image complète, la valeur de ce paramètre est \"None\". Mais si nous voulons trouver l'histogramme d'une région particulière de l'image, nous devons créer une image de masque.\n",
    "    <li><b>histSize</b>: ce paramètre représente le nombre BIN. Il doit être indiqué entre crochets.\n",
    "    <li><b>range</b>: c'est notre plage. Normalement, c'est [0,256].\n",
    "    </ul>\n",
    "Commençons donc par un exemple d'image. Chargeons simplement une image en mode niveaux de gris et trouvons son histogramme complet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread ('images/road.jpg', 0)\n",
    "hist = cv2.calcHist ([img], [0], None, [256], [0,256])\n",
    "print(hist[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>hist</b> est un tableau 256x1, chaque valeur correspond au nombre de pixels dans cette image avec sa valeur de pixel correspondante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread ('images/road.jpg', 0)\n",
    "hist = cv2.calcHist ([img], [0], None, [256], [0,256])\n",
    "cv2.imshow(\"Road\", img)\n",
    "plt.plot(hist)\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme avec NumPy\n",
    "<p>\n",
    "    Numpy fournit également une fonction, <b>np.histogram ()</b>. Ainsi, au lieu de la fonction calcHist (), on peut essayer la ligne ci-dessous:\n",
    "    </p>\n",
    "    <center><i>hist,bins = np.histogram(img.ravel(),256,[0,256])</i></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "hist,bins = np.histogram(img.ravel(),256,[0,256])\n",
    "plt.plot(hist)\n",
    "plt.show()\n",
    "print(bins) #Nombre de bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramme avec Matplotlib\n",
    "<p>\n",
    "    Matplotlib est livré avec une fonction de tracé d'histogramme : <b>matplotlib.pyplot.hist ()</b>\n",
    "\n",
    "Matplotlib créé directement l'histogramme et le trace. On n'a pas besoin d'utiliser la fonction calcHist () ou np.histogram () pour trouver l'histogramme. Voir le code ci-dessous:\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('images/road.jpg',0)\n",
    "cv2.imshow(\"Road\", img)\n",
    "plt.hist(img.ravel(),256,[0,256])\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Le principe du threshold est simple. Si la valeur d'un pixel est supérieure à une valeur de seuil, une valeur lui est attribuée (par exemple la couleur blanche), sinon une autre valeur (par exemple la couleur noire) lui est affectée. La fonction utilisée est <b>cv2.threshold</b>. \n",
    "</p>\n",
    "<p>Le premier argument de la fonction est l'image source, <u>qui devrait être une image en niveaux de gris</u>. Le deuxième argument est la valeur de seuil qui est utilisée pour classer les valeurs de pixels. Le troisième argument est le maxVal qui représente la valeur à donner si la valeur du pixel est supérieure (parfois inférieure à) la valeur seuil. OpenCV fournit différents styles de seuillage et il est indiqué dans le quatrième paramètre de la fonction. Les différents types sont:</p>\n",
    "<ul>\n",
    "    <li>cv2.THRESH_BINARY\n",
    "    <li>cv2.THRESH_BINARY_INV\n",
    "    <li>cv2.THRESH_TRUNC\n",
    "    <li>cv2.THRESH_TOZERO\n",
    "    <li>cv2.THRESH_TOZERO_INV\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('images/threshold.jpg',0)\n",
    "ret,thresh1 = cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "ret,thresh2 = cv2.threshold(img,127,255,cv2.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv2.threshold(img,127,255,cv2.THRESH_TRUNC)\n",
    "ret,thresh4 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO)\n",
    "ret,thresh5 = cv2.threshold(img,127,255,cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "cv2.imshow(\"Original Image\",img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/threshold.jpg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face and Eyes Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/face_detection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etapes à suivre :\n",
    "<ol>\n",
    "    <li><u>Etape 1</u> : Nous avons besoin d'une image, bien sûr. Ensuite il faut créer un classifieur en cascade (Cascade Classifier) qui contient les caractéristiques du visage (et des yeux) qui seront utilisées dans le code pour déterminer le visage et les yeux.\n",
    "    <li><u>Etape 2</u> : Utiliser OpenCV pour lire une image et le fichier de caractéristiques. L'image sera ensuite convertie en une matrice NumPy. Cette matrice sera utilisée pour connaître les coordonnées du visage et des yeux.\n",
    "    <li><u>Etape 3</u> : Afficher l'image en encadrant le visage et les yeux par des rectangles.\n",
    "    </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "img = cv2.imread(\"messi5.jpg\")\n",
    "\n",
    "#gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)        \n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes=eye_cascade.detectMultiScale(roi_color)\n",
    "    for (ex, ey, ew, eh) in eyes:\n",
    "        cv2.rectangle(roi_color, (ex, ey),(ex+ew, ey+eh),(0,255,0),2)\n",
    "cv2.imshow('Messi',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explications\n",
    "<ol>\n",
    "    <li> <i>face_cascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")</i> et <i>\n",
    "        eye_cascade = cv2.CascadeClassifier(\"haarcascade_eye.xml\")</i> : permettent de créer des classifieurs pour détecter le visage et les yeux respectivement.\n",
    "<li><i>faces = face_cascade.detectMultiScale(img, 1.3, 5)</i> : méthode pour chercher les coordonnées du rectangle délimitant le visage.\n",
    "<li>L'argument <i>scaleFactor</i> : décroit la valeur de la forme par 5%, jusqu'à ce que le visage soit trouvé. Plus que cette valeur est plus petite, plus que le résultat est meilleur.</li>\n",
    "<li> <img src=\"images/rectangle.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
